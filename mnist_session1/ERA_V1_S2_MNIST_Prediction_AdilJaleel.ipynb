{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJptKBxALl-u",
        "outputId": "6d84a40a-d7ae-408b-f6dc-7f1fe372b5b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "import torch ## importing torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F ## importing torch neural network module\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary ## To see the model summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "this cell checks the availability of GPU\n",
        "'''\n",
        "use_cuda = torch.cuda.is_available() # is cuda available\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")  # confirmation of cuda is available \n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Owi1LBNY8L",
        "outputId": "089c0f9c-2220-4f5d-c79a-492abedc6ef0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The cell looks into the data loading\n",
        "'''\n",
        "# Size of a batch must be more than or equal to one and less than or equal to the number of samples in the training dataset.\n",
        "batch_size = 128 #We have to start with a random batch size and then update after one run, see how much RAM is used and iterate with new batch size\n",
        "## Number of Physical Processor is in power of 2 and hence Virtual Processor should always be in power of 2. \n",
        "#train data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([   \n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,)) \n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True)   \n",
        "# Compose is similar to pipeline, the list of transforms\n",
        "# Loading the data and convert to tensor , tensor helps to send data to GPU by converting to tensor float objects with data standardisation (Between 0 to 1.0)\n",
        "# Normalisation- Bring the image similar. 0.1307 and 0.3081 is widely used for MNIST\n",
        "# Data loader is like a for loop- using multiple images\n",
        "\n",
        "#test data\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True)\n",
        "\n",
        "## Same for the test data from the training "
      ],
      "metadata": {
        "id": "EQZaZRGcNLtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f9ea90-1bae-4974-abb4-e491e720652d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 220735282.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 85366944.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 115863484.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7063599.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Notes on our naive model\n",
        "\n",
        "We are going to write a network based on what we have learnt so far. \n",
        "\n",
        "The size of the input image is 28x28x1. We are going to add as many layers as required to reach RF = 32 \"atleast\". "
      ],
      "metadata": {
        "id": "r3gEjf-xMb-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstDNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FirstDNN, self).__init__()\n",
        "    # For Edges and Gradient\n",
        "    # Pixel Size: 28x28\n",
        "    # r_in:1, n_in:28, j_in:1, s:1, r_out:3, n_out:28, j_out:1\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)  ## Convolution- 1 input channel ,32 output channel, 3x3 kernel\n",
        "    \n",
        "    # r_in:3 , n_in:28 , j_in:1 , s:1 , r_out:5 , n_out:28 , j_out:1\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, padding=1) # Convolution- 32 input channel ,64 output channel, 3x3 kernel\n",
        "    \n",
        "    \n",
        "    # r_in:5 , n_in:28 , j_in:1 , s:2 , r_out:6 , n_out:14 , j_out:2\n",
        "    self.pool1 = nn.MaxPool2d(2, 2) # Max Pooling\n",
        "    \n",
        "    # Textures and patterns\n",
        "    # r_in:6, n_in:14 , j_in:2 , s:1 , r_out:10 , n_out:14 , j_out:2\n",
        "    self.conv3 = nn.Conv2d(64, 128, 3, padding=1) # Convolution- 64 input channel ,128 output channel, 3x3 kernel\n",
        "    \n",
        "    # r_in:10 , n_in:14 , j_in:2 , s:1 , r_out:14 , n_out:14 , j_out:2\n",
        "    self.conv4 = nn.Conv2d(128, 256, 3, padding = 1) # Convolution- 128 input channel ,256 output channel, 3x3 kernel\n",
        "    \n",
        "    # r_in:14 , n_in:14 , j_in:2 , s:2 , r_out:16 , n_out:7 , j_out:4\n",
        "    self.pool2 = nn.MaxPool2d(2, 2) # Max Pooling \n",
        "    \n",
        "    # Objects\n",
        "    # r_in:16 , n_in:7 , j_in:4 , s:1 , r_out:24 , n_out:5 , j_out:4\n",
        "    self.conv5 = nn.Conv2d(256, 512, 3) # Convolution- 256 input channel ,512 output channel, 3x3 kernel\n",
        "    \n",
        "    # r_in:24 , n_in:5 , j_in:4 , s:1 , r_out:32 , n_out:3 , j_out:4\n",
        "    self.conv6 = nn.Conv2d(512, 1024, 3) # Convolution- 512 input channel ,1024 output channel, 3x3 kernel\n",
        "    \n",
        "    # r_in:32 , n_in:3 , j_in:4 , s:1 , r_out:40 , n_out:1 , j_out:4\n",
        "    self.conv7 = nn.Conv2d(1024, 10, 3) # Convolution- 1024 input channel ,10 output channel, 3x3 kernel\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))) ## Relu(Conv1) + Relu(Conv2) + MaxPool\n",
        "    x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x))))) ## Relu(Conv3) + Relu(Conv4) + MaxPool\n",
        "    x = F.relu(self.conv6(F.relu(self.conv5(x))))  ## Relu(Conv5) + Relu(Conv6)\n",
        "#    x = F.relu(self.conv7(x)) ## Relu(Conv7)\n",
        "    x =self.conv7(x) ## By removing the Relu func, you will get maximum accuracy\n",
        "\n",
        "    x = x.view(-1, 10)   # View will reshape the tensor. -1 means that the first dimension will be automatically picked based on the second dimension\n",
        "    return F.log_softmax(x) ## Log softmax normalize the output of a network to a probability distribution over predicted output classes,\n",
        "##Softmax is generated for tensor to lie between 0-1 and their sum is 1. Log Softmax is mainly for NLLLoss\n",
        "\n",
        "'''\n",
        "Setting the feed for the different layers. Relu is the activation function. It stands for Rectified Linear Unit\n",
        "'''"
      ],
      "metadata": {
        "id": "Sir2LmSVLr_4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5bf839cb-c217-400a-d1a4-590224621c7d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSetting the feed for the different layers. Relu is the activation function. It stands for Rectified Linear Unit\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FirstDNN().to(device) # Sending the model architecture to the CUDA device"
      ],
      "metadata": {
        "id": "sxICO4TTNt2H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Summary\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M__MtFIYNwXa",
        "outputId": "c5cd4ef1-03cc-468c-a1e0-9cff522b6568"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
            "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
            "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
            "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
            "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
            "================================================================\n",
            "Total params: 6,379,786\n",
            "Trainable params: 6,379,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.51\n",
            "Params size (MB): 24.34\n",
            "Estimated Total Size (MB): 25.85\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-7e0466dec43e>:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x) ## Log softmax normalize the output of a network to a probability distribution over predicted output classes,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm ## TQDM is a function which is used for time calculation\n",
        "'''\n",
        "Function for training the model\n",
        "'''\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train() \n",
        "    pbar = tqdm(train_loader)         \n",
        "    for batch_idx, (data, target) in enumerate(pbar): ##Batch_IDx - Get batch id, \n",
        "        data, target = data.to(device), target.to(device) \n",
        "        optimizer.zero_grad()              ###  Reset the gradients before proceeding to the next iteration or batch. \n",
        "        output = model(data)        # The negative log likelihood loss.\n",
        "        loss = F.nll_loss(output, target) # Maximize the probability of choosing the correct category by minimizing the negative log likelihood\n",
        "        loss.backward()  # Back propogation based on loss and gradients are calculated.\n",
        "        optimizer.step() # Performs a single optimization step (parameter update) based on the loss function. The weights get updated based on the loss. \n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}') ## TQDM bar for seeing the progress of the training\n",
        "\n",
        "'''\n",
        "Function for prediction of the model\n",
        "'''\n",
        "def test(model, device, test_loader):\n",
        "    model.eval() # Model evaluation on the test data\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad(): # For test data, there is no requirement for no gradient calculation\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data) # Output for the model\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()  \n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset))) ## Calculating the accuracy of the model based on the loss"
      ],
      "metadata": {
        "id": "g_vlC-bdNzo1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Various optimisation algorithms are implemented by the package torch.optim.\n",
        "Stochastic gradient descent is implemented (optionally with momentum).\n",
        "A method for iteratively improving an objective function with sufficient smoothness qualities is called SGD.\n",
        "SGD's momentum only serves to shorten the convergence time.\n",
        "In order to minimise the loss function, learning rate defines the step size at each iteration.\n",
        "'''\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 2): ## If model goes on all images in the dataset,it is one epoch.\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0FYVWkGOFBS",
        "outputId": "a7eaa26c-651c-4ffe-90bf-f2dbdb9b4ee4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]<ipython-input-4-7e0466dec43e>:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x) ## Log softmax normalize the output of a network to a probability distribution over predicted output classes,\n",
            "loss=0.10209507495164871 batch_id=468: 100%|██████████| 469/469 [00:32<00:00, 14.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0552, Accuracy: 9812/10000 (98%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# When batch decreased, accuracy increases/decreases but loss also increased\n",
        "## Epoch increases, time to run increase\n",
        "## When changed momentum from 0.9 to 0.3 , accuracy decreases and loss increases\n",
        "## When changed lr from 0.01 to 0.1 , accuracy decreases badly and loss also increases high\n",
        "## lr=0.05, momentum=0.9, accuracy= 39% \n",
        "## When batch increased, time for one epoch is less"
      ],
      "metadata": {
        "id": "reIBU667OG_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}